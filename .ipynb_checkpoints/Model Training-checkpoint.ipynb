{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c3a5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "de37bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"L:\\\\ML-Assignment\\\\training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a341ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(df.groupby(\"Sentiment Level\"))\n",
    "\n",
    "\n",
    "negative = splits[0][1]\n",
    "positive = splits[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9687221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "number = rand.randint(0,500000)\n",
    "positive = positive[number : number + 50000]\n",
    "\n",
    "number = rand.randint(0,500000)\n",
    "negative = negative[number: number + 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b35dac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([positive, negative], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7c39e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "442be708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_concat[\"joined_Tweet\"], df_concat[\"Sentiment Level\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f82e00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train.to_frame().to_numpy(dtype=np.string_)).astype(np.string_)\n",
    "x_test = np.asarray(x_test.to_frame().to_numpy(dtype=np.string_)).astype(np.string_)\n",
    "y_train = np.asarray(y_train.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "y_test = np.asarray(y_test.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "\n",
    "\n",
    "def create_label(y):\n",
    "    counter = 0\n",
    "    result = np.array([[]])\n",
    "    if y[0] == np.string_(\"0\"):\n",
    "        result = np.array([[1,0]])\n",
    "    elif y[0] == np.string_(\"4\"):\n",
    "        result = np.array([[0,1]])\n",
    "    \n",
    "    for i in y: \n",
    "        if counter > 0:\n",
    "            if i == np.string_(\"0\"):\n",
    "                result = np.append(result, np.array([[1,0]]), axis = 0)\n",
    "            elif i == np.string_(\"4\"):\n",
    "                result = np.append(result, np.array([[0,1]]), axis = 0)\n",
    "        counter+=1\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "new_y_train = create_label(y_train)   \n",
    "new_y_test = create_label(y_test)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "943b18ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'Elaine might be coming down for RPattz day x']\n",
      " [b'Wow I checked out Artfire That Is awesome']\n",
      " [b'Another damp and rainy day here in Sicily Feel like sneaking into bed and sleep all day Wish I could drink coffee to keep me alive']\n",
      " ...\n",
      " [b'Omg Its only 11 and there is nothing to do']\n",
      " [b'Getting fitted for bridesmaid dresses with lacee alysa cory aaron and mikela']\n",
      " [b'yes yes you really do']]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "98c3eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, load_model \n",
    "from tensorflow.keras.layers import Dense, TextVectorization\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5016387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "MAX_FEATURES = 200000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "155db006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name = \"Nice_model\")\n",
    "model.add(Input(shape=(1,), dtype = tf.string))\n",
    "vectorize_layer = TextVectorization(split = \"whitespace\", \n",
    "                                    ngrams=(1,2),\n",
    "                                    output_mode = \"tf_idf\")\n",
    "\n",
    "vectorize_layer.adapt(np.asarray(df_concat[\"joined_Tweet\"].to_numpy(dtype=np.string_)).astype(np.string_))\n",
    "\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L1\"))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L2\"))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L3\"))\n",
    "model.add(Dense(units = 64, activation = \"relu\", name = \"L4\"))\n",
    "model.add(Dense(units = 2, activation = \"sigmoid\", name = \"Output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics = \"accuracy\")\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "74597c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nice_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_17 (Text  (None, 484946)           1         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " L1 (Dense)                  (None, 128)               62073216  \n",
      "                                                                 \n",
      " L2 (Dense)                  (None, 128)               16512     \n",
      "                                                                 \n",
      " L3 (Dense)                  (None, 128)               16512     \n",
      "                                                                 \n",
      " L4 (Dense)                  (None, 64)                8256      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,114,627\n",
      "Trainable params: 62,114,626\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "21d56f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea586",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, new_y_text)\n",
    "\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "06ea39fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 912s 608ms/step - loss: 0.4643 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.8005\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 817s 544ms/step - loss: 0.2894 - accuracy: 0.8879 - val_loss: 0.4888 - val_accuracy: 0.7947\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 827s 551ms/step - loss: 0.1394 - accuracy: 0.9544 - val_loss: 0.5938 - val_accuracy: 0.7895\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 831s 554ms/step - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.7775 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 811s 541ms/step - loss: 0.0495 - accuracy: 0.9860 - val_loss: 0.8972 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209fc222ca0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"L:\\\\ML-Assignment\\\\Logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(x_train, new_y_train,\n",
    "         epochs=5,\n",
    "         batch_size=50,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         verbose = 1,\n",
    "         validation_data = (x_test, new_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ad4e56e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25004), started 3:50:19 ago. (Use '!kill 25004' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7789044336bc0171\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7789044336bc0171\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0b8e3a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: L:\\ML-Assignment\\Model\\Model_02\\assets\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"L:\\\\ML-Assignment\\\\Model\\\\Model_02\"\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3cd38603",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3d900c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_dir)\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "bdda9465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[b'awesome see speaking WordCampNOLA Wish I lived closer']\n"
     ]
    }
   ],
   "source": [
    "print(new_y_train[6])\n",
    "print(x_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "52628381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np \n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def predict(model, input, stopword = stopwords):\n",
    "    input = input.lower()\n",
    "    input = re.sub(\"@[^\\s]+\", \"\", input)\n",
    "    input = re.sub('r[^\\w\\s]+', \"\", input)\n",
    "    input = input.split(\" \")\n",
    "    \n",
    "    \n",
    "    emoji = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u2640-\\u2642\" \n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\ufe0f\"  # dingbats\n",
    "    u\"\\u3030\"\n",
    "    \"]+\", re.UNICODE)\n",
    "    \n",
    "    input = [re.sub(emoji,\"\",x) for x in input]\n",
    "    input = [x.encode(\"ascii\",\"ignore\").decode() for x in input]\n",
    "    input = [contractions.fix(x) for x in input]\n",
    "    input = ' '.join(map(str, input))\n",
    "    input = word_tokenize(input, language = 'english')\n",
    "    #input = [x for x in input if x not in stopwords]\n",
    "    input = [x for x in input if not x.isdigit()]\n",
    "    input = ' '.join(map(str, input))\n",
    "    filtered_text = input\n",
    "    \n",
    "    x_input = np.array([input], dtype = np.string_)\n",
    "    y = model.predict(x_input)\n",
    "    result = \"\"\n",
    "    \n",
    "    if y[0][0] == y[0].max():\n",
    "        result = \"Depression Detected\"\n",
    "    elif y[0][1] == y[0].max():\n",
    "        result = \"No Depression\"\n",
    "        \n",
    "    return (result, y, filtered_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e6fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text: lol\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Filtered Text: lol\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.08175925\n",
      "No Depression:  0.9104283\n",
      "Enter Text: tears\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filtered Text: tears\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.92656714\n",
      "No Depression:  0.06328783\n",
      "Enter Text: sad\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: sad\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.83755267\n",
      "No Depression:  0.1433904\n",
      "Enter Text: im sad\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: i am sad\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.9584544\n",
      "No Depression:  0.043380015\n",
      "Enter Text: happy birthday\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: happy birthday\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.00042154995\n",
      "No Depression:  0.99959475\n",
      "Enter Text: happy little kid \n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filtered Text: happy little kid\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.013569449\n",
      "No Depression:  0.986436\n",
      "Enter Text: kill the kid\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Filtered Text: kill the kid\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.059949704\n",
      "No Depression:  0.9332637\n",
      "Enter Text: kill myself\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filtered Text: kill myself\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.61897045\n",
      "No Depression:  0.35997188\n",
      "Enter Text: happily ever after\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "Filtered Text: happily ever after\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.10784968\n",
      "No Depression:  0.8773507\n",
      "Enter Text: tragedy\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: tragedy\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.7725237\n",
      "No Depression:  0.21225436\n",
      "Enter Text: my god\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Filtered Text: my god\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.74698246\n",
      "No Depression:  0.24166904\n",
      "Enter Text: pray for me\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filtered Text: pray for me\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.42537323\n",
      "No Depression:  0.5201457\n",
      "Enter Text: u know what im talking about \n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filtered Text: you know what i am talking about\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.0005858339\n",
      "No Depression:  0.99927026\n",
      "Enter Text: happy birthday\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: happy birthday\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.00042154995\n",
      "No Depression:  0.99959475\n",
      "Enter Text: happy easter\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: happy easter\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.054819427\n",
      "No Depression:  0.94956857\n",
      "Enter Text: sad easter\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: sad easter\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.83673346\n",
      "No Depression:  0.14405422\n",
      "Enter Text: ubuntu\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: ubuntu\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.15495858\n",
      "No Depression:  0.8267752\n",
      "Enter Text: @halsey022 kill yourself\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: kill yourself\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.10953666\n",
      "No Depression:  0.88075954\n",
      "Enter Text: kill myself\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "Filtered Text: kill myself\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.61897045\n",
      "No Depression:  0.35997188\n",
      "Enter Text: suicide\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: suicide\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.57513136\n",
      "No Depression:  0.3963869\n",
      "Enter Text: ive been wanting to kill myself lately\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i have been wanting to kill myself lately\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.74712175\n",
      "No Depression:  0.22735693\n",
      "Enter Text: this is not okay \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: this is not okay\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.92932874\n",
      "No Depression:  0.060882635\n",
      "Enter Text: im not okay\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: i am not okay\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.5130963\n",
      "No Depression:  0.48473135\n",
      "Enter Text: i am an asshole\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am an asshole\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.70063585\n",
      "No Depression:  0.2954141\n",
      "Enter Text: im a cunty\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am a cunty\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.28621882\n",
      "No Depression:  0.7035268\n",
      "Enter Text: im a cunt\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am a cunt\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.28177452\n",
      "No Depression:  0.71064436\n",
      "Enter Text: im a failure\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am a failure\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.8337631\n",
      "No Depression:  0.13526532\n",
      "Enter Text: failure\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: failure\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.7062284\n",
      "No Depression:  0.28064597\n",
      "Enter Text: lmao\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: lmao\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.03280647\n",
      "No Depression:  0.9665542\n",
      "Enter Text: are you kidding me? \n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Filtered Text: are you kidding me ?\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.09846082\n",
      "No Depression:  0.89909565\n",
      "Enter Text: this is not real \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: this is not real\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.95179075\n",
      "No Depression:  0.046220563\n",
      "Enter Text: this cant be real \n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Filtered Text: this can not be real\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.9889142\n",
      "No Depression:  0.008214828\n",
      "Enter Text: for god's sake\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: for god 's sake\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.1320966\n",
      "No Depression:  0.8624968\n",
      "Enter Text: god is with you \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: god is with you\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.04909057\n",
      "No Depression:  0.9529918\n",
      "Enter Text: may the force be with us \n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filtered Text: may the force be with us\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.10055613\n",
      "No Depression:  0.9121553\n",
      "Enter Text: u little punk\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: you little punk\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.7493209\n",
      "No Depression:  0.23946321\n",
      "Enter Text: sheesh \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: sheesh\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.32710603\n",
      "No Depression:  0.651715\n",
      "Enter Text: who are you \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: who are you\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.87644744\n",
      "No Depression:  0.1157219\n",
      "Enter Text: who are you? \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: who are you ?\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.87644744\n",
      "No Depression:  0.1157219\n",
      "Enter Text: please\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: please\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.80095595\n",
      "No Depression:  0.18977259\n",
      "Enter Text: not like this \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: not like this\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.99959886\n",
      "No Depression:  0.0002736246\n",
      "Enter Text: i m begging you \n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "Filtered Text: i m begging you\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.71464336\n",
      "No Depression:  0.26422453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text: please let us go\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Filtered Text: please let us go\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.0005536793\n",
      "No Depression:  0.9995823\n",
      "Enter Text: please let us go \n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: please let us go\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.0005536793\n",
      "No Depression:  0.9995823\n",
      "Enter Text: unreal \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: unreal\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.7470855\n",
      "No Depression:  0.24776192\n",
      "Enter Text: awesome!\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: awesome !\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.028422277\n",
      "No Depression:  0.97363245\n",
      "Enter Text: great\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Filtered Text: great\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.049847927\n",
      "No Depression:  0.9513794\n",
      "Enter Text: worse\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Filtered Text: worse\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.7586453\n",
      "No Depression:  0.22384225\n",
      "Enter Text: you are the worse\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: you are the worse\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.22909613\n",
      "No Depression:  0.7707279\n",
      "Enter Text: i am the worse\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Filtered Text: i am the worse\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.46480092\n",
      "No Depression:  0.5099261\n",
      "Enter Text: im the worse\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am the worse\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.46480092\n",
      "No Depression:  0.5099261\n",
      "Enter Text: you are a failure\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: you are a failure\n",
      "Model Result: No Depression\n",
      "Depression Detected:  0.04079398\n",
      "No Depression:  0.95885235\n",
      "Enter Text: im a failure\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Filtered Text: i am a failure\n",
      "Model Result: Depression Detected\n",
      "Depression Detected:  0.8337631\n",
      "No Depression:  0.13526532\n"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    x = input(\"Enter Text: \")\n",
    "    \n",
    "    if x == \"exit\":\n",
    "        break\n",
    "    \n",
    "    y = predict(model, x)\n",
    "    print(\"Filtered Text: \" + y[2])\n",
    "    print(\"Model Result: \" + y[0])\n",
    "    print(\"Depression Detected: \", y[1][0][0])\n",
    "    print(\"No Depression: \", y[1][0][1])\n",
    "    \n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d75b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb4db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
