{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "de37bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the filtered data \n",
    "df = pd.read_csv(\"L:\\\\ML-Assignment\\\\filtered_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a341ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 2 classes according to the sentiment levels \n",
    "splits = list(df.groupby(\"Sentiment Level\"))\n",
    "\n",
    "\n",
    "negative = splits[0][1]\n",
    "positive = splits[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9687221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly select 50000 features from each class \n",
    "import random as rand\n",
    "\n",
    "number = rand.randint(0,500000)\n",
    "positive = positive[number : number + 50000]\n",
    "\n",
    "number = rand.randint(0,500000)\n",
    "negative = negative[number: number + 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b35dac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat 2 classes into 1 dataframe\n",
    "df_concat = pd.concat([positive, negative], axis = 0)\n",
    "\n",
    "#shuffle the sequence of the dataframe\n",
    "df_concat = df_concat.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "442be708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataframes into random train and test subsets, the method returns lists\n",
    "#default ratio in splitting the training and testing set is 3:1 \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_concat[\"joined_Tweet\"], df_concat[\"Sentiment Level\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f82e00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the lists into numpy arrays of type string \n",
    "x_train = np.asarray(x_train.to_frame().to_numpy(dtype=np.string_)).astype(np.string_)\n",
    "x_test = np.asarray(x_test.to_frame().to_numpy(dtype=np.string_)).astype(np.string_)\n",
    "y_train = np.asarray(y_train.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "y_test = np.asarray(y_test.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "\n",
    "\n",
    "#create labels in the form of a 2 dimensional array to split the labels into 2 distinct classes \n",
    "def create_label(y):\n",
    "    counter = 0\n",
    "    result = np.array([[]])\n",
    "    if y[0] == np.string_(\"0\"):\n",
    "        result = np.array([[1,0]])\n",
    "    elif y[0] == np.string_(\"4\"):\n",
    "        result = np.array([[0,1]])\n",
    "    \n",
    "    for i in y: \n",
    "        if counter > 0:\n",
    "            if i == np.string_(\"0\"):\n",
    "                result = np.append(result, np.array([[1,0]]), axis = 0)\n",
    "            elif i == np.string_(\"4\"):\n",
    "                result = np.append(result, np.array([[0,1]]), axis = 0)\n",
    "        counter+=1\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#create labels from the y_train and y_test \n",
    "new_y_train = create_label(y_train)   \n",
    "new_y_test = create_label(y_test)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c3eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, load_model \n",
    "from tensorflow.keras.layers import Dense, TextVectorization\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "155db006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "#create our machine learning model \n",
    "model = Sequential(name = \"Nice_model\")\n",
    "model.add(Input(shape=(1,), dtype = tf.string))\n",
    "\n",
    "#text vectorization is needed to convert the texts into integers \n",
    "vectorize_layer = TextVectorization(split = \"whitespace\", \n",
    "                                    ngrams=(1,2),\n",
    "                                    output_mode = \"tf_idf\")\n",
    "\n",
    "vectorize_layer.adapt(np.asarray(df_concat[\"joined_Tweet\"].to_numpy(dtype=np.string_)).astype(np.string_))\n",
    "\n",
    "\n",
    "#add the layers into our models \n",
    "model.add(vectorize_layer)\n",
    "\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L1\"))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L2\"))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L3\"))\n",
    "model.add(Dense(units = 64, activation = \"relu\", name = \"L4\"))\n",
    "model.add(Dense(units = 2, activation = \"sigmoid\", name = \"Output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics = \"accuracy\")\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "74597c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Nice_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_17 (Text  (None, 484946)           1         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " L1 (Dense)                  (None, 128)               62073216  \n",
      "                                                                 \n",
      " L2 (Dense)                  (None, 128)               16512     \n",
      "                                                                 \n",
      " L3 (Dense)                  (None, 128)               16512     \n",
      "                                                                 \n",
      " L4 (Dense)                  (None, 64)                8256      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,114,627\n",
      "Trainable params: 62,114,626\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the score of our model \n",
    "score = model.evaluate(x_test, new_y_test)\n",
    "\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "06ea39fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 912s 608ms/step - loss: 0.4643 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.8005\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 817s 544ms/step - loss: 0.2894 - accuracy: 0.8879 - val_loss: 0.4888 - val_accuracy: 0.7947\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 827s 551ms/step - loss: 0.1394 - accuracy: 0.9544 - val_loss: 0.5938 - val_accuracy: 0.7895\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 831s 554ms/step - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.7775 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 811s 541ms/step - loss: 0.0495 - accuracy: 0.9860 - val_loss: 0.8972 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209fc222ca0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start the training here \n",
    "log_dir = \"L:\\\\ML-Assignment\\\\Logs\\\\Logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram freq = 1)\n",
    "\n",
    "model.fit(x_train, new_y_train,\n",
    "         epochs=5,\n",
    "         batch_size=50,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         verbose = 1,\n",
    "         validation_data = (x_test, new_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4e56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext tensorboard\n",
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8e3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model, remember to change the model number in the file name \n",
    "model_dir = \"L:\\\\ML-Assignment\\\\Model\\\\Model_02\"\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3cd38603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the model after it is saved \n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d900c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "#load the model \n",
    "model = load_model(model_dir)\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52628381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the input like how we cleaned the data for the model \n",
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np \n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def predict(model, input, stopword = stopwords):\n",
    "    input = input.lower()\n",
    "    input = re.sub(\"@[^\\s]+\", \"\", input)\n",
    "    input = re.sub('r[^\\w\\s]+', \"\", input)\n",
    "    input = input.split(\" \")\n",
    "\n",
    "    input = [x.encode(\"ascii\",\"ignore\").decode() for x in input]\n",
    "    input = [contractions.fix(x) for x in input]\n",
    "    input = ' '.join(map(str, input))\n",
    "    input = word_tokenize(input, language = 'english')\n",
    "    #input = [x for x in input if x not in stopwords]\n",
    "    input = [x for x in input if not x.isdigit()]\n",
    "    input = ' '.join(map(str, input))\n",
    "    filtered_text = input\n",
    "    \n",
    "    x_input = np.array([input], dtype = np.string_)\n",
    "    y = model.predict(x_input)\n",
    "    result = \"\"\n",
    "    \n",
    "    if y[0][0] == y[0].max():\n",
    "        result = \"High probability of depression\"\n",
    "    elif y[0][1] == y[0].max():\n",
    "        result = \"Low probabiltity of depression\"\n",
    "        \n",
    "    return (result, y, filtered_text)\n",
    "\n",
    "#return a list wit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a5e6fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text: exit\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "#test the model with inputs \n",
    "while True: \n",
    "    x = input(\"Enter Text: \")\n",
    "    \n",
    "    if x == \"quit\" or x == \"exit\":\n",
    "        break\n",
    "    \n",
    "    y = predict(model, x)\n",
    "    print(\"Filtered Text: \" + y[2])\n",
    "    print(\"Model Result: \" + y[0])\n",
    "    print(\"Probability of depression: \", \"{:.4f}\".format(y[1][0][0] * 100))\n",
    "\n",
    "    \n",
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
