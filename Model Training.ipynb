{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the filtered data \n",
    "#please change the directory according to where you stored the file \n",
    "df = pd.read_csv(\"L:\\\\ML-Assignment\\\\training_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype({\"joined_text\" : \"string\" , \"class\" : \"string\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f53ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 2 classes according to the sentiment levels \n",
    "splits = list(df.groupby(\"class\"))\n",
    "\n",
    "\n",
    "negative = splits[0][1]\n",
    "positive1 = splits[1][1]\n",
    "positive2 = splits[2][1]\n",
    "suicidal = splits[4][1]\n",
    "\n",
    "positive = pd.concat([positive1, positive2], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32749b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly select 50000 features from each class \n",
    "import random as rand\n",
    "\n",
    "number = rand.randint(0,750000)\n",
    "new_positive = positive[number : number + 50000]\n",
    "\n",
    "number = rand.randint(0,750000)\n",
    "new_negative = negative[number: number + 50000]\n",
    "\n",
    "number = rand.randint(0,75000)\n",
    "new_suicidal = suicidal[number: number+ 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35dac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat 3 classes into 1 dataframe\n",
    "df_concat = pd.concat([new_positive, new_negative, new_suicidal], axis = 0)\n",
    "\n",
    "#shuffle the sequence of the dataframe\n",
    "df_concat = df_concat.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442be708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataframes into random train and test subsets, the method returns lists\n",
    "#default ratio in splitting the training and testing set is 3:1 \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_concat[\"joined_text\"], df_concat[\"class\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the lists into numpy arrays of type string \n",
    "x_train = np.asarray(x_train.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "x_test = np.asarray(x_test.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "y_train = np.asarray(y_train.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "y_test = np.asarray(y_test.to_frame().to_numpy(dtype=np.string_).astype(np.string_))\n",
    "\n",
    "\n",
    "#create labels in the form of a 2 dimensional array to split the labels into 2 distinct classes \n",
    "def create_label(y):\n",
    "    counter = 0\n",
    "    result = np.array([[]])\n",
    "    if y[0] == np.string_(\"0\"):\n",
    "        result = np.array([[1,0,0]])\n",
    "    elif y[0] == np.string_(\"4\"):\n",
    "        result = np.array([[0,1,0]])\n",
    "    elif y[0] == np.string_(\"suicide\"):\n",
    "        result = np.array([[0,0,1]])\n",
    "    \n",
    "    for i in y: \n",
    "        if counter > 0:\n",
    "            if i == np.string_(\"0\"):\n",
    "                result = np.append(result, np.array([[1,0,0]]), axis = 0)\n",
    "            elif i == np.string_(\"4\"):\n",
    "                result = np.append(result, np.array([[0,1,0]]), axis = 0)\n",
    "            elif i == np.string_(\"suicide\"):\n",
    "                result = np.append(result, np.array([[0,0,1]]), axis = 0)\n",
    "        counter+=1\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#create labels from the y_train and y_test \n",
    "new_y_train = create_label(y_train)   \n",
    "new_y_test = create_label(y_test)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3be70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_y_train[30])\n",
    "print(y_train[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, load_model \n",
    "from tensorflow.keras.layers import Dense, TextVectorization, LSTM, Dropout\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155db006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our machine learning model \n",
    "model = Sequential(name = \"Nice_model\")\n",
    "model.add(Input(shape=(1,), dtype = tf.string))\n",
    "\n",
    "#text vectorization is needed to convert the texts into integers \n",
    "vectorize_layer = TextVectorization(split = \"whitespace\", \n",
    "                                    ngrams=(1,2),\n",
    "                                    output_mode = \"tf_idf\")\n",
    "\n",
    "vectorize_layer.adapt(np.asarray(df_concat[\"joined_text\"].to_numpy(dtype=np.string_)).astype(np.string_))\n",
    "\n",
    "\n",
    "#add the layers into our models \n",
    "model.add(vectorize_layer)\n",
    "\n",
    "model.add(Dropout(0.2, input_shape=(128,)))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L1\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 128, activation = \"relu\", name = \"L2\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 64, activation = \"relu\", name = \"L3\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 3, activation = \"sigmoid\", name = \"Output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = \"accuracy\")\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74597c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the score of our model \n",
    "score = model.evaluate(x_test, new_y_test)\n",
    "\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the training here \n",
    "#please change the directory according to where you wish to store the logs \n",
    "log_dir = \"L:\\\\ML-Assignment\\\\Logs\\\\Logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "history = model.fit(x_train, new_y_train,\n",
    "         epochs=4,\n",
    "         batch_size=64,\n",
    "         callbacks=[tensorboard_callback],\n",
    "         verbose = 1,\n",
    "         validation_data = (x_test, new_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb37869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model, remember to change the model number in the file name \n",
    "#please change the directory according to where you wish to store the model \n",
    "model_dir = \"L:\\\\ML-Assignment\\\\Model\\\\Model_07\"\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd38603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the model after it is saved \n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d900c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model \n",
    "model = load_model(model_dir)\n",
    "\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52628381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the input like how we cleaned the data for the model \n",
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "def predict(model, input, stopword = stopwords):\n",
    "    input = input.lower()\n",
    "    input = re.sub(\"@[^\\s]+\", '', input)\n",
    "    input = re.sub(r'[^\\w\\s]', '', input)\n",
    "    input = input.split(\" \")\n",
    "\n",
    "    input = [x.encode(\"ascii\",\"ignore\").decode() for x in input]\n",
    "    input = [contractions.fix(x) for x in input]\n",
    "    input = ' '.join(map(str, input))\n",
    "    input = word_tokenize(input, language = 'english')\n",
    "    #input = [x for x in input if x not in stopwords]\n",
    "    input = [x for x in input if not x.isdigit()]\n",
    "    input = ' '.join(map(str, input))\n",
    "    filtered_text = input\n",
    "    \n",
    "    x_input = np.array([input], dtype = np.string_)\n",
    "    y = model.predict(x_input)\n",
    "    result = \"\"\n",
    "    \n",
    "    if y[0][0] == y[0].max():\n",
    "        result = \"High probability of depression\"\n",
    "    elif y[0][1] == y[0].max():\n",
    "        result = \"Low probabiltity of depression\"\n",
    "    elif y[0][2] == y[0].max():\n",
    "        result = \"Suicidal thoughts\"\n",
    "        \n",
    "    return (result, y, filtered_text)\n",
    "\n",
    "#return a list wit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e6fba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the model with inputs \n",
    "while True: \n",
    "    x = input(\"Enter Text: \")\n",
    "    \n",
    "    if x == \"quit\" or x == \"exit\":\n",
    "        break\n",
    "    \n",
    "    y = predict(model, x)\n",
    "    print(\"Filtered Text: \" + y[2])\n",
    "    print(\"Model Result: \" + y[0])\n",
    "    print(\"Probability of depression: \", \"{:.4f}%\".format(y[1][0][0] * 100))\n",
    "    print(\"No depression: \", \"{:.4f}%\".format(y[1][0][1] * 100) )\n",
    "    print(\"Suicidal thought: \", \"{:.4f}%\".format(y[1][0][2] * 100) )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
